<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>workflows with sklearn | pots and pans.</title><meta name=keywords content><meta name=description content="Let´s take advantage of things that are already built. Im referring to sklearn and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.
A. Splits First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set."><meta name=author content><link rel=canonical href=http://rafasacaan.github.io/pots-and-pans/posts/a-simple-workflow/><link crossorigin=anonymous href=/pots-and-pans/assets/css/stylesheet.min.55a7d73879d73f559167b5679c19057296a7f4626666a82a81a4b1d68d060c3a.css integrity="sha256-VafXOHnXP1WRZ7VnnBkFcpan9GJmZqgqgaSx1o0GDDo=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/pots-and-pans/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://rafasacaan.github.io/pots-and-pans/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://rafasacaan.github.io/pots-and-pans/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://rafasacaan.github.io/pots-and-pans/favicon-32x32.png><link rel=apple-touch-icon href=http://rafasacaan.github.io/pots-and-pans/apple-touch-icon.png><link rel=mask-icon href=http://rafasacaan.github.io/pots-and-pans/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.97.3"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="workflows with sklearn"><meta property="og:description" content="Let´s take advantage of things that are already built. Im referring to sklearn and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.
A. Splits First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set."><meta property="og:type" content="article"><meta property="og:url" content="http://rafasacaan.github.io/pots-and-pans/posts/a-simple-workflow/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-11T11:00:00-03:00"><meta property="article:modified_time" content="2022-04-11T11:00:00-03:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="workflows with sklearn"><meta name=twitter:description content="Let´s take advantage of things that are already built. Im referring to sklearn and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.
A. Splits First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://rafasacaan.github.io/pots-and-pans/posts/"},{"@type":"ListItem","position":2,"name":"workflows with sklearn","item":"http://rafasacaan.github.io/pots-and-pans/posts/a-simple-workflow/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"workflows with sklearn","name":"workflows with sklearn","description":"Let´s take advantage of things that are already built. Im referring to sklearn and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.\nA. Splits First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set.","keywords":[],"articleBody":"Let´s take advantage of things that are already built. Im referring to sklearn and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.\nA. Splits First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set. Don´t fool yourself fitting out over the test set! Its there only for a final check and having a firm-ground metric on how our model can generalize out there in the wild.\nSecond, let´s define our kfold so we can have reproducible results from now on. Two things:\n  Choose your n_folds wisely: for little data, we need similar distributions over the target, 3-folds may be enough. Otherwise, 5-fold or even a 10-fold may be necessary.\n  Take a minute and think about which type of folding strategy to choose. Group folds, stratify multiple labels?\n  So, our first piece of code should look similar to the following.\nfrom sklearn.model_selection import KFold, train_test_split  X = df.drop(columns=['y']) y = df.y.values  # Define a test set folds = 5 X_train, X_test, y_train, y_test = train_test_split(  X,  y,  test_size=(1/folds),  random_state=0,  stratify=y)  # Make folds kfold = KFold(  n_splits=folds - 1 ,  shuffle=True,  random_state=2) B. Data cleaning This step should take care of cleaning the data so that it is ready to use. For example: strip, filter, transform, divide, concatenate columns, strings, data types, etc. One or multiple pandas functions should be enough. When done, generate a csv to keep track of your experiment.\nC. Data preprocessing Here starts the fun part. For preprocessing, we should focus on partitioning columns into numerical and categorical and transforming them. Then, concatenate both and gather all the data, so we can pass it on to a model.\nThe trick here is to use custom transformers so we have the flexibility of doing whatever we want. Two cases arise:\n from sklearn.base import BaseEstimator, TransformerMixin   # Case #1: no fit method required class DropFeatureSelector(BaseEstimator, TransformerMixin):  def __init__(self, variables):  self.variables = variables   def fit(self, X, y = None):  return self   def transform(self, X):  X_dropped = X.drop(self.variables, axis = 1)  self.columns = X_dropped.columns  return X_dropped   # Case #2: fit method required  class OneHotEncoderCustom(BaseEstimator, TransformerMixin):  def __init__(self, variables):  self.variables = variables  self.ohe = OneHotEncoder(drop='first', handle_unknown='ignore')   def fit(self, X, y = None):  X_ = X.loc[:,self.variables]  self.ohe.fit(X_)  return self   def transform(self, X):  X_ = X.loc[:,self.variables]   # get one-hot encoded feature in df format  X_transformed = pd.DataFrame(self.ohe.transform(X_).toarray(), columns= self.ohe.get_feature_names_out())   # Remove columns that are one hot encoded in original df  X.drop(self.variables, axis= 1, inplace=True)   # Add one hot encoded feature to original df  X[self.ohe.get_feature_names_out()] = X_transformed[self.ohe.get_feature_names_out()].values  return X Understanding custom transformers, now we should be able to build a pipeline in the following fashion.\nfrom sklearn.pipeline import Pipeline from sklearn.preprocessing import OrdinalEncoder from sklearn.impute import SimpleImputer from sklearn.compose import ColumnTransformer from sklearn.ensemble import HistGradientBoostingRegressor   # Categorical transformers ordinal_encoder = OrdinalEncoder(categories=categories)  categorical_preprocessor = Pipeline(  steps=[  #('replacer', custom_replacer(variables=['a','b'])),  ('encoder', ordinal_encoder)  ] )   # Numerical transformers imputer = SimpleImputer(strategy='mean')  numerical_preprocessor = Pipeline(  steps=[  ('imputer', imputer)  ] )  # Complete preprocessor preprocessor = ColumnTransformer(  transformers=[  ('categorical', categorical_preprocessor, categorical_columns),  ('numerical', numerical_preprocessor, numerical_columns)  ] )  # Add estimator gbrt_pipeline = Pipeline([  ('preprocessor', preprocessor),  ('model', HistGradientBoostingRegressor(categorical_features=range(4))) ]) We can also check graphically our pipeline.\nfrom sklearn import set_config  set_config(display=\"diagram\") gbrt_pipeline D. Evaluate our model Now, for a certain set of pre-defined hyperparameters, we can evaluate our pipeline.\ndef evaluate (model, X, y, cv):  cv_results = cross_validate(  model,  X,  y,  cv=cv,  scoring={'neg_mean_absolute_error','neg_root_mean_squared_error'},  )  rmse = -cv_results['test_neg_root_mean_squared_error']  mae = -cv_results['test_neg_mean_absolute_error']   print(  f\"Mean Absolute Error: {mae.mean():.3f}+/- {mae.std():.3f}\\n\"  f\"Root Mean Squared Error: {rmse.mean():.3f}+/- {rmse.std():.3f}\"  )   evaluate(gbrt_pipeline, X, y, cv=ts_cv) E. Grid Search Now, we can test any hyperparameter from the preprocessign pipeline and estimator.\nfrom sklearn.model_selection import GridSearchCV  def grid_search(model, X, y, params, cv):   grid_search = GridSearchCV(  gbrt_pipeline,  param_grid=params,  cv=ts_cv,  scoring={'neg_mean_absolute_error','neg_root_mean_squared_error'},  refit='neg_root_mean_squared_error',  n_jobs=-1)   grid_search.fit(X, y)   print(-grid_search.best_score_)  print(grid_search.best_params_)   # Run grid search params = {  \"preprocessor__numerical__imputer__strategy\": ['mean','median'],  \"model__learning_rate\": [0.01, 0.1], }  grid_search(my_pipeline, X_train, y_train, params, ts_cv) F. Special note on metrics! (Taken from calmcode.io) Often, it is important to create custom metrics that respond to business questions.\nfrom sklearn.model_selection import GridSearchCV from sklearn.metrics import precision_score, recall_score, make_scorer  def min_recall_precision(est, X, y_true, sample_weight=None):  y_pred = est.predict(X)  recall = recall_score(y_true, y_pred)  precision = precision_score(y_true, y_pred)  return min(recall, precision)  grid = GridSearchCV(  estimator=LogisticRegression(max_iter=1000),  param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},  scoring={'precision': make_scorer(precision_score),  'recall': make_scorer(recall_score),  'min_both': min_recall_precision}, # custom metric  refit='min_both',  return_train_score=True,  cv=10,  n_jobs=-1 ) grid.fit(X, y, sample_weight=np.log(1 + df['Amount'] )) ","wordCount":"767","inLanguage":"en","datePublished":"2022-04-11T11:00:00-03:00","dateModified":"2022-04-11T11:00:00-03:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://rafasacaan.github.io/pots-and-pans/posts/a-simple-workflow/"},"publisher":{"@type":"Organization","name":"pots and pans.","logo":{"@type":"ImageObject","url":"http://rafasacaan.github.io/pots-and-pans/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://rafasacaan.github.io/pots-and-pans/ accesskey=h title="pots and pans. (Alt + H)">pots and pans.</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://rafasacaan.github.io/pots-and-pans/>Home</a>&nbsp;»&nbsp;<a href=http://rafasacaan.github.io/pots-and-pans/posts/>Posts</a></div><h1 class=post-title>workflows with sklearn<sup><span class=entry-isdraft>&nbsp;&nbsp;[draft]</span></sup></h1><div class=post-meta><span title="2022-04-11 11:00:00 -0300 -0300">April 11, 2022</span>&nbsp;·&nbsp;4 min</div></header><div class=post-content><p>Let´s take advantage of things that are already built. Im referring to <strong>sklearn</strong> and the whole variety of beautiful utilities and functions that help us make our lives simpler and stay curious, testing and trying out new stuff. This will be simple and straight to the bone.</p><h2 id=a-splits>A. Splits<a hidden class=anchor aria-hidden=true href=#a-splits>#</a></h2><p>First, lets take the whole data and leave aside a testing chunk. Then, we can run cross validation on training set and when we think we are ready, we can check our scores on the test set. Don´t fool yourself fitting out over the test set! Its there only for a final check and having a firm-ground metric on how our model can generalize out there in the wild.</p><p>Second, let´s define our <strong>kfold</strong> so we can have reproducible results from now on. Two things:</p><ul><li><p>Choose your <strong>n_folds</strong> wisely: for little data, we need similar distributions over the target, 3-folds may be enough. Otherwise, 5-fold or even a 10-fold may be necessary.</p></li><li><p>Take a minute and think about which type of <strong>folding strategy</strong> to choose. Group folds, stratify multiple labels?</p></li></ul><p>So, our first piece of code should look similar to the following.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> KFold, train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;y&#39;</span>])
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>y<span style=color:#f92672>.</span>values
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define a test set</span>
</span></span><span style=display:flex><span>folds <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X, 
</span></span><span style=display:flex><span>    y, 
</span></span><span style=display:flex><span>    test_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span><span style=color:#f92672>/</span>folds), 
</span></span><span style=display:flex><span>    random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, 
</span></span><span style=display:flex><span>    stratify<span style=color:#f92672>=</span>y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Make folds</span>
</span></span><span style=display:flex><span>kfold <span style=color:#f92672>=</span> KFold(
</span></span><span style=display:flex><span>    n_splits<span style=color:#f92672>=</span>folds <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span> , 
</span></span><span style=display:flex><span>    shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>    random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><h2 id=b-data-cleaning>B. Data cleaning<a hidden class=anchor aria-hidden=true href=#b-data-cleaning>#</a></h2><p>This step should take care of cleaning the data so that it is ready to use. For example: strip, filter, transform, divide, concatenate columns, strings, data types, etc. One or multiple <strong>pandas</strong> functions should be enough. When done, generate a csv to keep track of your experiment.</p><h2 id=c-data-preprocessing>C. Data preprocessing<a hidden class=anchor aria-hidden=true href=#c-data-preprocessing>#</a></h2><p>Here starts the fun part. For preprocessing, we should focus on partitioning columns into <strong>numerical</strong> and <strong>categorical</strong> and transforming them. Then, concatenate both and gather all the data, so we can pass it on to a model.</p><p>The trick here is to use <strong>custom transformers</strong> so we have the flexibility of doing whatever we want. Two cases arise:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.base <span style=color:#f92672>import</span> BaseEstimator, TransformerMixin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Case #1: no fit method required</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DropFeatureSelector</span>(BaseEstimator, TransformerMixin):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, variables):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>variables <span style=color:#f92672>=</span> variables
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X, y <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>transform</span>(self, X):
</span></span><span style=display:flex><span>        X_dropped <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>drop(self<span style=color:#f92672>.</span>variables, axis <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> X_dropped<span style=color:#f92672>.</span>columns
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> X_dropped
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Case #2: fit method required</span>
</span></span><span style=display:flex><span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>OneHotEncoderCustom</span>(BaseEstimator, TransformerMixin):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, variables):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>variables <span style=color:#f92672>=</span> variables
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>ohe <span style=color:#f92672>=</span> OneHotEncoder(drop<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;first&#39;</span>, handle_unknown<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ignore&#39;</span>)
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X, y <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        X_ <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>loc[:,self<span style=color:#f92672>.</span>variables]
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>ohe<span style=color:#f92672>.</span>fit(X_)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self
</span></span><span style=display:flex><span>      
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>transform</span>(self, X):
</span></span><span style=display:flex><span>        X_ <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>loc[:,self<span style=color:#f92672>.</span>variables]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># get one-hot encoded feature in df format</span>
</span></span><span style=display:flex><span>        X_transformed <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(self<span style=color:#f92672>.</span>ohe<span style=color:#f92672>.</span>transform(X_)<span style=color:#f92672>.</span>toarray(), columns<span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>ohe<span style=color:#f92672>.</span>get_feature_names_out())
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Remove columns that are one hot encoded in original df</span>
</span></span><span style=display:flex><span>        X<span style=color:#f92672>.</span>drop(self<span style=color:#f92672>.</span>variables, axis<span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Add one hot encoded feature to original df</span>
</span></span><span style=display:flex><span>        X[self<span style=color:#f92672>.</span>ohe<span style=color:#f92672>.</span>get_feature_names_out()] <span style=color:#f92672>=</span> X_transformed[self<span style=color:#f92672>.</span>ohe<span style=color:#f92672>.</span>get_feature_names_out()]<span style=color:#f92672>.</span>values
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> X   
</span></span></code></pre></div><p>Understanding custom transformers, now we should be able to build a pipeline in the following fashion.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OrdinalEncoder
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.impute <span style=color:#f92672>import</span> SimpleImputer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.compose <span style=color:#f92672>import</span> ColumnTransformer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> HistGradientBoostingRegressor
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Categorical transformers</span>
</span></span><span style=display:flex><span>ordinal_encoder <span style=color:#f92672>=</span> OrdinalEncoder(categories<span style=color:#f92672>=</span>categories)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>categorical_preprocessor <span style=color:#f92672>=</span> Pipeline(
</span></span><span style=display:flex><span>    steps<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>        <span style=color:#75715e>#(&#39;replacer&#39;, custom_replacer(variables=[&#39;a&#39;,&#39;b&#39;])),</span>
</span></span><span style=display:flex><span>        (<span style=color:#e6db74>&#39;encoder&#39;</span>, ordinal_encoder)
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Numerical transformers</span>
</span></span><span style=display:flex><span>imputer <span style=color:#f92672>=</span> SimpleImputer(strategy<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean&#39;</span>) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>numerical_preprocessor <span style=color:#f92672>=</span> Pipeline(
</span></span><span style=display:flex><span>    steps<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>      (<span style=color:#e6db74>&#39;imputer&#39;</span>, imputer)
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Complete preprocessor</span>
</span></span><span style=display:flex><span>preprocessor <span style=color:#f92672>=</span> ColumnTransformer(
</span></span><span style=display:flex><span>    transformers<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>      (<span style=color:#e6db74>&#39;categorical&#39;</span>, categorical_preprocessor, categorical_columns),
</span></span><span style=display:flex><span>      (<span style=color:#e6db74>&#39;numerical&#39;</span>, numerical_preprocessor, numerical_columns)
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Add estimator</span>
</span></span><span style=display:flex><span>gbrt_pipeline <span style=color:#f92672>=</span> Pipeline([
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;preprocessor&#39;</span>, preprocessor),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#39;model&#39;</span>, HistGradientBoostingRegressor(categorical_features<span style=color:#f92672>=</span>range(<span style=color:#ae81ff>4</span>)))
</span></span><span style=display:flex><span>])
</span></span></code></pre></div><p>We can also check graphically our pipeline.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> set_config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>set_config(display<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;diagram&#34;</span>)
</span></span><span style=display:flex><span>gbrt_pipeline
</span></span></code></pre></div><h2 id=d-evaluate-our-model>D. Evaluate our model<a hidden class=anchor aria-hidden=true href=#d-evaluate-our-model>#</a></h2><p>Now, for a certain set of pre-defined hyperparameters, we can evaluate our pipeline.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>evaluate</span> (model, X, y, cv):
</span></span><span style=display:flex><span>  cv_results <span style=color:#f92672>=</span> cross_validate(
</span></span><span style=display:flex><span>      model, 
</span></span><span style=display:flex><span>      X,
</span></span><span style=display:flex><span>      y,
</span></span><span style=display:flex><span>      cv<span style=color:#f92672>=</span>cv,
</span></span><span style=display:flex><span>      scoring<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;neg_mean_absolute_error&#39;</span>,<span style=color:#e6db74>&#39;neg_root_mean_squared_error&#39;</span>},
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>  rmse <span style=color:#f92672>=</span> <span style=color:#f92672>-</span>cv_results[<span style=color:#e6db74>&#39;test_neg_root_mean_squared_error&#39;</span>]
</span></span><span style=display:flex><span>  mae <span style=color:#f92672>=</span> <span style=color:#f92672>-</span>cv_results[<span style=color:#e6db74>&#39;test_neg_mean_absolute_error&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  print(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Mean Absolute Error:     </span><span style=color:#e6db74>{</span>mae<span style=color:#f92672>.</span>mean()<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> +/- </span><span style=color:#e6db74>{</span>mae<span style=color:#f92672>.</span>std()<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Root Mean Squared Error: </span><span style=color:#e6db74>{</span>rmse<span style=color:#f92672>.</span>mean()<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> +/- </span><span style=color:#e6db74>{</span>rmse<span style=color:#f92672>.</span>std()<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>evaluate(gbrt_pipeline, X, y, cv<span style=color:#f92672>=</span>ts_cv)
</span></span></code></pre></div><h2 id=e-grid-search>E. Grid Search<a hidden class=anchor aria-hidden=true href=#e-grid-search>#</a></h2><p>Now, we can test any hyperparameter from the preprocessign pipeline and estimator.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>grid_search</span>(model, X, y, params, cv):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    grid_search <span style=color:#f92672>=</span> GridSearchCV(
</span></span><span style=display:flex><span>    gbrt_pipeline, 
</span></span><span style=display:flex><span>    param_grid<span style=color:#f92672>=</span>params, 
</span></span><span style=display:flex><span>    cv<span style=color:#f92672>=</span>ts_cv,
</span></span><span style=display:flex><span>    scoring<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;neg_mean_absolute_error&#39;</span>,<span style=color:#e6db74>&#39;neg_root_mean_squared_error&#39;</span>},
</span></span><span style=display:flex><span>    refit<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;neg_root_mean_squared_error&#39;</span>,
</span></span><span style=display:flex><span>    n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    grid_search<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#f92672>-</span>grid_search<span style=color:#f92672>.</span>best_score_)
</span></span><span style=display:flex><span>    print(grid_search<span style=color:#f92672>.</span>best_params_)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Run grid search</span>
</span></span><span style=display:flex><span>params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;preprocessor__numerical__imputer__strategy&#34;</span>: [<span style=color:#e6db74>&#39;mean&#39;</span>,<span style=color:#e6db74>&#39;median&#39;</span>],
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;model__learning_rate&#34;</span>: [<span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>0.1</span>],
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>grid_search(my_pipeline, X_train, y_train, params, ts_cv)
</span></span></code></pre></div><h2 id=f-special-note-on-metrics>F. Special note on metrics!<a hidden class=anchor aria-hidden=true href=#f-special-note-on-metrics>#</a></h2><p>(Taken from calmcode.io) Often, it is important to create custom metrics that respond to business questions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> precision_score, recall_score, make_scorer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>min_recall_precision</span>(est, X, y_true, sample_weight<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    y_pred <span style=color:#f92672>=</span> est<span style=color:#f92672>.</span>predict(X)
</span></span><span style=display:flex><span>    recall <span style=color:#f92672>=</span> recall_score(y_true, y_pred)
</span></span><span style=display:flex><span>    precision <span style=color:#f92672>=</span> precision_score(y_true, y_pred)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> min(recall, precision)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> GridSearchCV(
</span></span><span style=display:flex><span>    estimator<span style=color:#f92672>=</span>LogisticRegression(max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>),
</span></span><span style=display:flex><span>    param_grid<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;class_weight&#39;</span>: [{<span style=color:#ae81ff>0</span>: <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>: v} <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>30</span>)]},
</span></span><span style=display:flex><span>    scoring<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;precision&#39;</span>: make_scorer(precision_score),
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#39;recall&#39;</span>: make_scorer(recall_score),
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#39;min_both&#39;</span>: min_recall_precision}, <span style=color:#75715e># custom metric</span>
</span></span><span style=display:flex><span>    refit<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;min_both&#39;</span>,
</span></span><span style=display:flex><span>    return_train_score<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    cv<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>grid<span style=color:#f92672>.</span>fit(X, y, sample_weight<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>log(<span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> df[<span style=color:#e6db74>&#39;Amount&#39;</span>] ))
</span></span></code></pre></div></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022 <a href=http://rafasacaan.github.io/pots-and-pans/>pots and pans.</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>